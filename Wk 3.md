**Wk 3**

- Filtering is an efficient mechanism for finding patterns
- Filters respond most strongly to pattern elements that look like the filters 
- How to detect various features?
  - different filter kernels obtain different activation/feature maps
  - use training images to tells what filter kernels are useful (by loss function)
- CNN: 3D volumes of neurons (stack of convolutional layers, fully connected layers, pooling layers)
  - convolutional layer
    - num of filter kernels = num of output activation maps
    - connections are local in the spatial dimension
    - parameter sharing: filter coefficients in the kernel are the same
  - fully-connected layer
    - all neurons in the preceding layer is connected to each neuron in the next layer
  - pooling layer
    - reduces spatial size of feature map, reduce model parameters
    - overlap/non-overlap, average/max pooling
    - translation invariant: same pooled feature even when the image undergoes small translations 
    - receptive field: part of image visible to a neuron (although connections are local, neurons in the higher layers could see large portions of the image)

- LeNet (Trained on MINIST digit dataset; Average pooling, Sigmoid or tanh nonlinearity)
  - INPUT 32 x 32 (filter kernel: 5 x 5)
  - C1: 6@28 x 28
  - S2: 6@14 x 14
  - C3: 16@10 x 10
  - S4: 16@5 x 5
  - C5: 120 
  - F6: 84
  - OUTPUT: 10 
- AlexNet (1.2M images of 1000 classes; Max pooling; ReLU nonlinearity)
  - 8 layers, 650K neurons, 60M parameters
- GoogLeNet, Inception module
  - filter size is another hyperparameter
  - Inception module uses filters of different size in the same layer
  - concatenate all filter results as output
  - use 1x1 convolution to reduce complexity by reducing no. of channels (dimensionality reduction)
  - increases width, depth of network
  - all convolutions use ReLU, including 1x1 convolution for reduction/projection
    - from input of HxWxC1, with C2 filters (1x1xC1 each), output is HxWxC2; usually C2 < C1